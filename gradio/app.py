#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Gradio ë°ëª¨ ì•±: Langfuse ë°ì´í„°ì…‹ í‰ê°€ ì¸í„°í˜ì´ìŠ¤

ì´ ë°ëª¨ëŠ” ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
1. Langfuse ì„œë²„ì—ì„œ ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ
2. ë°ì´í„°ì…‹ ì„ íƒ ì‹œ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
3. íŠ¹ì • ì•„ì´í…œ ì„ íƒ ì‹œ inputê³¼ metadata ë‚´ìš© í‘œì‹œ
4. run ì‹¤í–‰ ì‹œ turnë³„ í‰ê°€ ìˆ˜í–‰ ë° ê²°ê³¼ í‘œì‹œ
"""

import os
import sys
import json
import time
import uuid
import gradio as gr
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import warnings

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore")

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
SCRIPT_DIR = os.path.abspath(os.path.dirname(__file__))
WORK_DIR = os.path.abspath(os.path.join(SCRIPT_DIR, ".."))
ENV_FILE = os.path.join(WORK_DIR, ".env.params")

from dotenv import load_dotenv
load_dotenv(ENV_FILE)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(WORK_DIR)

# Langfuse ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from langfuse import get_client, Langfuse
    from langfuse.langchain import CallbackHandler
except ImportError:
    raise ImportError("Error: Langfuse ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”. (pip install langfuse)")

# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage

# IFEval ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    sys.path.append(os.path.join(WORK_DIR, "ifeval"))
    from ifeval.evaluation_main import test_instruction_following_strict, test_instruction_following_loose
    from ifeval.evaluation_main import InputExample, OutputExample
except ImportError:
    raise ImportError("Warning: ifeval ëª¨ë“ˆì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ê¸°ì¡´ í‰ê°€ í´ë˜ìŠ¤ ì„í¬íŠ¸
sys.path.append(os.path.join(WORK_DIR, "scripts"))
from ifeval_langchain_with_langfuse import LangfuseEvaluator, EvaluationResult, EvaluationScore

class GradioEvaluationApp:
    """Gradio í‰ê°€ ì•± í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì•± ì´ˆê¸°í™”"""
        self.langfuse_client = None
        self.evaluator = None
        self.current_dataset = None
        self.current_item = None
        self.current_messages = []
        self.current_scores = []
        self.current_model = "gpt-4o-mini"
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
        self.available_models = [
            "gpt-4o",
            "gpt-4o-mini", 
            "gpt-4.1",
            "gpt-4.1-mini",
            "gpt-4.1-nano",
            "gpt-3.5-turbo"
        ]
        
        # Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self._initialize_langfuse()
        
        # í‰ê°€ê¸° ì´ˆê¸°í™” (ê¸°ë³¸ ëª¨ë¸ë¡œ)
        self._initialize_evaluator()
    
    def _initialize_langfuse(self):
        """Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            self.langfuse_client = get_client()
            auth_status = self.langfuse_client.auth_check()
            if not auth_status:
                raise Exception("Langfuse ì¸ì¦ ì‹¤íŒ¨")
            print("âœ… Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ Langfuse ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _initialize_evaluator(self, model_name: str = None):
        """í‰ê°€ê¸° ì´ˆê¸°í™”"""
        try:
            if model_name:
                self.current_model = model_name
            
            self.evaluator = LangfuseEvaluator(
                model_name=self.current_model,
                temperature=0.6,
                verbose=False
            )
            print(f"âœ… í‰ê°€ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {self.current_model})")
        except Exception as e:
            print(f"âŒ í‰ê°€ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def get_dataset_list(self) -> List[str]:
        """ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # Langfuse APIë¡œ ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            datasets = self.langfuse_client.api.datasets.list()
            return [dataset.name for dataset in datasets]
        except Exception as e:
            print(f"âŒ ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            return ["multi-if-ko", "General_MultiIF_English", "Telco_MultiIF_Korean"]
    
    def load_dataset(self, dataset_name: str) -> Tuple[List[str], str]:
        """ë°ì´í„°ì…‹ ë¡œë“œ"""
        if not dataset_name:
            return [], "ë°ì´í„°ì…‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
        
        try:
            self.current_dataset = self.evaluator.get_dataset(dataset_name)
            item_list = []
            for idx, item in enumerate(self.current_dataset.items):
                key = item.metadata.get("key", f"item_{idx}")
                language = item.metadata.get("language", "Unknown")
                item_list.append(f"{key} ({language})")
            
            return item_list, f"âœ… ë°ì´í„°ì…‹ '{dataset_name}' ë¡œë“œ ì™„ë£Œ ({len(item_list)}ê°œ ì•„ì´í…œ)"
        except Exception as e:
            return [], f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}"
    
    def select_item(self, item_selection: str) -> Tuple[str, str]:
        """ì•„ì´í…œ ì„ íƒ"""
        if not item_selection or not self.current_dataset:
            return "", ""
        
        try:
            # ì•„ì´í…œ ì¸ë±ìŠ¤ ì¶”ì¶œ
            item_idx = 0
            for idx, item in enumerate(self.current_dataset.items):
                key = item.metadata.get("key", f"item_{idx}")
                language = item.metadata.get("language", "Unknown")
                if f"{key} ({language})" == item_selection:
                    item_idx = idx
                    break
            
            self.current_item = self.current_dataset.items[item_idx]
            
            # input ë‚´ìš© í‘œì‹œ
            input_content = "### Input ë‚´ìš©:\n"
            for key, value in self.current_item.input.items():
                input_content += f"**{key}:**\n```json\n{json.dumps(value, indent=2, ensure_ascii=False)}\n```\n\n"
            
            # metadata ë‚´ìš© í‘œì‹œ
            metadata_content = "### Metadata ë‚´ìš©:\n"
            metadata_content += f"```json\n{json.dumps(self.current_item.metadata, indent=2, ensure_ascii=False)}\n```"
            
            return input_content, metadata_content
        except Exception as e:
            return f"âŒ ì•„ì´í…œ ì„ íƒ ì‹¤íŒ¨: {e}", ""
    
    def change_model(self, model_name: str) -> str:
        """ëª¨ë¸ ë³€ê²½"""
        try:
            self._initialize_evaluator(model_name)
            return f"âœ… ëª¨ë¸ì„ '{model_name}'ìœ¼ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤."
        except Exception as e:
            return f"âŒ ëª¨ë¸ ë³€ê²½ ì‹¤íŒ¨: {e}"
    
    def run_evaluation(self, progress=gr.Progress()) -> Tuple[List[Tuple[str, str]], str]:
        """í‰ê°€ ì‹¤í–‰"""
        if not self.current_item:
            return [], "ì•„ì´í…œì„ ì„ íƒí•´ì£¼ì„¸ìš”."
        
        try:
            # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
            self.current_messages = []
            self.current_scores = []
            chat_history = []
            
            # í„´ ìˆ˜ í™•ì¸
            max_turn = 0
            for key in self.current_item.input:
                if key.startswith("turn_") and key[5:].isdigit():
                    turn_num = int(key[5:])
                    max_turn = max(max_turn, turn_num)
            
            if max_turn == 0:
                return [], "âŒ ì´ ì•„ì´í…œì—ëŠ” í„´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # ê° í„´ë³„ë¡œ í‰ê°€ ìˆ˜í–‰
            run_name = f"gradio_eval_{self.current_model}_{int(time.time())}"
            messages = []
            
            progress_step = 1.0 / max_turn
            
            for turn_index in range(1, max_turn + 1):
                progress(progress_step * turn_index, desc=f"Turn {turn_index}/{max_turn} í‰ê°€ ì¤‘... (ëª¨ë¸: {self.current_model})")
                
                # í„´ë³„ í‰ê°€ ìˆ˜í–‰
                result, messages = self.evaluator.eval_process_by_turn(
                    self.current_item, 
                    turn_index, 
                    run_name, 
                    messages
                )
                
                # ì±„íŒ… ê¸°ë¡ ì¶”ê°€
                if len(messages) >= 2:
                    user_message = str(messages[-2].content)
                    ai_message = str(messages[-1].content)
                    
                    chat_history.append((user_message, ai_message))
                
                # ì ìˆ˜ ê¸°ë¡
                self.current_scores.append({
                    "turn": turn_index,
                    "score": result.score,
                    "error": result.error
                })
            
            # ì ìˆ˜ í‘œì‹œ ë¬¸ìì—´ ìƒì„±
            scores_display = self._format_scores()
            
            return chat_history, scores_display
            
        except Exception as e:
            return [], f"âŒ í‰ê°€ ì‹¤í–‰ ì‹¤íŒ¨: {e}"
    
    def _format_scores(self) -> str:
        """ì ìˆ˜ í¬ë§·íŒ…"""
        if not self.current_scores:
            return "ì ìˆ˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        scores_text = f"### í„´ë³„ ì ìˆ˜ (ëª¨ë¸: {self.current_model}):\n\n"
        
        for score_info in self.current_scores:
            turn = score_info["turn"]
            score = score_info["score"]
            error = score_info["error"]
            
            scores_text += f"**Turn {turn}:**\n"
            
            if error:
                scores_text += f"âŒ ì˜¤ë¥˜: {error}\n\n"
            else:
                scores_text += f"- Overall Score: {score.overall_score:.3f}\n"
                scores_text += f"- Strict Prompt Score: {score.strict_prompt_score:.3f}\n"
                scores_text += f"- Strict Instruction Score: {score.strict_inst_score:.3f}\n"
                scores_text += f"- Loose Prompt Score: {score.loose_prompt_score:.3f}\n"
                scores_text += f"- Loose Instruction Score: {score.loose_inst_score:.3f}\n\n"
        
        # í‰ê·  ì ìˆ˜ ê³„ì‚°
        if self.current_scores:
            valid_scores = [s for s in self.current_scores if s["error"] is None]
            if valid_scores:
                avg_overall = sum(s["score"].overall_score for s in valid_scores) / len(valid_scores)
                avg_strict_prompt = sum(s["score"].strict_prompt_score for s in valid_scores) / len(valid_scores)
                avg_strict_inst = sum(s["score"].strict_inst_score for s in valid_scores) / len(valid_scores)
                avg_loose_prompt = sum(s["score"].loose_prompt_score for s in valid_scores) / len(valid_scores)
                avg_loose_inst = sum(s["score"].loose_inst_score for s in valid_scores) / len(valid_scores)
                
                scores_text += "### í‰ê·  ì ìˆ˜:\n"
                scores_text += f"- Overall Score: {avg_overall:.3f}\n"
                scores_text += f"- Strict Prompt Score: {avg_strict_prompt:.3f}\n"
                scores_text += f"- Strict Instruction Score: {avg_strict_inst:.3f}\n"
                scores_text += f"- Loose Prompt Score: {avg_loose_prompt:.3f}\n"
                scores_text += f"- Loose Instruction Score: {avg_loose_inst:.3f}\n"
        
        return scores_text

def create_gradio_app() -> gr.Blocks:
    """Gradio ì•± ìƒì„±"""
    
    # ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    app = GradioEvaluationApp()
    
    # ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    dataset_list = app.get_dataset_list()
    
    with gr.Blocks(title="MT-IF-Eval: Langfuse ë°ì´í„°ì…‹ í‰ê°€ ë°ëª¨", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸš€ MT-IF-Eval: Langfuse ë°ì´í„°ì…‹ í‰ê°€ ë°ëª¨")
        gr.Markdown("ì´ ë°ëª¨ëŠ” Langfuseì—ì„œ mt-if-eval ë°ì´í„°ì…‹ì„ ê°€ì ¸ì™€ ë©€í‹°í„´ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        
        with gr.Row():
            with gr.Column(scale=1):
                # ëª¨ë¸ ì„ íƒ
                model_dropdown = gr.Dropdown(
                    choices=app.available_models,
                    label="ğŸ¤– LLM ëª¨ë¸ ì„ íƒ",
                    value=app.current_model
                )
                
                model_status = gr.Textbox(
                    label="ëª¨ë¸ ìƒíƒœ",
                    value=f"í˜„ì¬ ëª¨ë¸: {app.current_model}",
                    interactive=False
                )
                
                # ë°ì´í„°ì…‹ ì„ íƒ
                dataset_dropdown = gr.Dropdown(
                    choices=dataset_list,
                    label="ğŸ“Š ë°ì´í„°ì…‹ ì„ íƒ",
                    value=dataset_list[0] if dataset_list else None
                )
                
                dataset_status = gr.Textbox(
                    label="ë°ì´í„°ì…‹ ìƒíƒœ",
                    value="ë°ì´í„°ì…‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
                    interactive=False
                )
                
                # ì•„ì´í…œ ì„ íƒ
                item_dropdown = gr.Dropdown(
                    choices=[],
                    label="ğŸ“„ ì•„ì´í…œ ì„ íƒ",
                    value=None
                )
                
                # í‰ê°€ ì‹¤í–‰ ë²„íŠ¼
                run_button = gr.Button("ğŸš€ í‰ê°€ ì‹¤í–‰", variant="primary")
                
            with gr.Column(scale=2):
                # ì•„ì´í…œ ì •ë³´ í‘œì‹œ
                with gr.Tab("Input ë‚´ìš©"):
                    input_display = gr.Markdown("ì•„ì´í…œì„ ì„ íƒí•˜ë©´ input ë‚´ìš©ì´ í‘œì‹œë©ë‹ˆë‹¤.")
                
                with gr.Tab("Metadata ë‚´ìš©"):
                    metadata_display = gr.Markdown("ì•„ì´í…œì„ ì„ íƒí•˜ë©´ metadata ë‚´ìš©ì´ í‘œì‹œë©ë‹ˆë‹¤.")
        
        with gr.Row():
            with gr.Column(scale=2):
                # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
                chat_interface = gr.Chatbot(
                    label="ğŸ’¬ ëŒ€í™” ê¸°ë¡",
                    height=800,
                    value=[]
                )
                
            with gr.Column(scale=1):
                # ì ìˆ˜ í‘œì‹œ
                scores_display = gr.Markdown(
                    "### ğŸ“Š ì ìˆ˜ ì •ë³´\ní‰ê°€ë¥¼ ì‹¤í–‰í•˜ë©´ í„´ë³„ ì ìˆ˜ê°€ í‘œì‹œë©ë‹ˆë‹¤.",
                    height=400
                )
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        def on_model_change(model_name):
            status = app.change_model(model_name)
            return status
        
        def on_dataset_change(dataset_name):
            item_list, status = app.load_dataset(dataset_name)
            return gr.update(choices=item_list, value=None), status
        
        def on_item_change(item_selection):
            input_content, metadata_content = app.select_item(item_selection)
            return input_content, metadata_content
        
        def on_run_evaluation(progress=gr.Progress()):
            chat_history, scores = app.run_evaluation(progress)
            return chat_history, scores
        
        # ì´ë²¤íŠ¸ ë°”ì¸ë”©
        model_dropdown.change(
            on_model_change,
            inputs=[model_dropdown],
            outputs=[model_status]
        )
        
        dataset_dropdown.change(
            on_dataset_change,
            inputs=[dataset_dropdown],
            outputs=[item_dropdown, dataset_status]
        )
        
        item_dropdown.change(
            on_item_change,
            inputs=[item_dropdown],
            outputs=[input_display, metadata_display]
        )
        
        run_button.click(
            on_run_evaluation,
            inputs=[],
            outputs=[chat_interface, scores_display]
        )
    
    return demo

if __name__ == "__main__":
    # ì•± ì‹¤í–‰
    demo = create_gradio_app()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_api=False
    )